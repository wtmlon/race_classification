nohup: ignoring input
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=3, bias=True)
  )
)
['BLACK', 'WHITE', 'YELLOW']
Epoch 0/29
----------
 train Loss: 0.4754 Acc: 0.8036
 val Loss: 0.2959 Acc: 0.8796

Epoch 1/29
----------
 train Loss: 0.2705 Acc: 0.8939
 val Loss: 0.2196 Acc: 0.9154

Epoch 2/29
----------
 train Loss: 0.2162 Acc: 0.9157
 val Loss: 0.1839 Acc: 0.9290

Epoch 3/29
----------
 train Loss: 0.1871 Acc: 0.9271
 val Loss: 0.1593 Acc: 0.9384

Epoch 4/29
----------
 train Loss: 0.1669 Acc: 0.9356
 val Loss: 0.1580 Acc: 0.9389

Epoch 5/29
----------
 train Loss: 0.1537 Acc: 0.9411
 val Loss: 0.1688 Acc: 0.9334

Epoch 6/29
----------
 train Loss: 0.1386 Acc: 0.9464
 val Loss: 0.1401 Acc: 0.9488

Epoch 7/29
----------
 train Loss: 0.1325 Acc: 0.9495
 val Loss: 0.1339 Acc: 0.9490

Epoch 8/29
----------
 train Loss: 0.1248 Acc: 0.9504
 val Loss: 0.1189 Acc: 0.9551

Epoch 9/29
----------
 train Loss: 0.1130 Acc: 0.9565
 val Loss: 0.1120 Acc: 0.9567

Epoch 10/29
----------
 train Loss: 0.1071 Acc: 0.9601
 val Loss: 0.1181 Acc: 0.9532

Epoch 11/29
----------
 train Loss: 0.0985 Acc: 0.9632
 val Loss: 0.1214 Acc: 0.9561

Epoch 12/29
----------
 train Loss: 0.0941 Acc: 0.9642
 val Loss: 0.1135 Acc: 0.9559

Epoch 13/29
----------
 train Loss: 0.0865 Acc: 0.9668
 val Loss: 0.1056 Acc: 0.9585

Epoch 14/29
----------
 train Loss: 0.0817 Acc: 0.9709
 val Loss: 0.1059 Acc: 0.9595

Epoch 15/29
----------
 train Loss: 0.0797 Acc: 0.9699
 val Loss: 0.1059 Acc: 0.9582

Epoch 16/29
----------
 train Loss: 0.0802 Acc: 0.9698
 val Loss: 0.1046 Acc: 0.9601

Epoch 17/29
----------
 train Loss: 0.0835 Acc: 0.9691
 val Loss: 0.1044 Acc: 0.9607

Epoch 18/29
----------
 train Loss: 0.0782 Acc: 0.9708
 val Loss: 0.1083 Acc: 0.9580

Epoch 19/29
----------
 train Loss: 0.0758 Acc: 0.9718
 val Loss: 0.1072 Acc: 0.9585

Epoch 20/29
----------
 train Loss: 0.0753 Acc: 0.9710
 val Loss: 0.1045 Acc: 0.9606

Epoch 21/29
----------
 train Loss: 0.0750 Acc: 0.9730
 val Loss: 0.1062 Acc: 0.9580

Epoch 22/29
----------
 train Loss: 0.0774 Acc: 0.9711
 val Loss: 0.1043 Acc: 0.9603

Epoch 23/29
----------
 train Loss: 0.0732 Acc: 0.9718
 val Loss: 0.1063 Acc: 0.9607

Epoch 24/29
----------
 train Loss: 0.0770 Acc: 0.9712
 val Loss: 0.1074 Acc: 0.9585

Epoch 25/29
----------
 train Loss: 0.0739 Acc: 0.9730
 val Loss: 0.1050 Acc: 0.9609

Epoch 26/29
----------
 train Loss: 0.0739 Acc: 0.9731
 val Loss: 0.1035 Acc: 0.9614

Epoch 27/29
----------
 train Loss: 0.0758 Acc: 0.9706
 val Loss: 0.1040 Acc: 0.9599

Epoch 28/29
----------
 train Loss: 0.0701 Acc: 0.9747
 val Loss: 0.1097 Acc: 0.9582

Epoch 29/29
----------
 train Loss: 0.0691 Acc: 0.9748
 val Loss: 0.1031 Acc: 0.9601

Train complete in 14m 30s
Best val Acc: 0.961384
Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f26e1676f28>
Traceback (most recent call last):
  File "/usr/lib/python3.5/weakref.py", line 117, in remove
TypeError: 'NoneType' object is not callable
